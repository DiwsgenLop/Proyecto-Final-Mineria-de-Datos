{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "024ba7aa",
   "metadata": {},
   "source": [
    "# Proyecto Final: Clasificación de Sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8cb321",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2944170571.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[73], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    from sklearn.naive_bayes import MultinomialNBimport torch\u001b[0m\n\u001b[1;37m                                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Librerías principales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import torch\n",
    "# Visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Preprocesamiento de texto\n",
    "import re\n",
    "from collections import Counter\n",
    "#Identificar palabras clave por sentimientos\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Configuracion\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "#Dividir el data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Importamos las librerias para los algoritmos\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# COLORES DE MATPLOT y tamaño de las gráficas\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c3bc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar stopwords si es necesario\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('spanish')) \n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c391a738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir stopwords en español\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "\n",
    "# Inicializar lematizador y stemmer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = SnowballStemmer(\"spanish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b453c1",
   "metadata": {},
   "source": [
    "<h1> Análisis Exploratorio de Datos (EDA) </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd547cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset\n",
    "dataset_path = \"Textos_Dataset_Completo.csv\"  # Cambia el path si es necesario\n",
    "dataset = pd.read_csv(dataset_path, encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cacd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar información básica\n",
    "print(\"Información del Dataset:\")\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905fc7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nVista preliminar del Dataset:\")\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a1a246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores nulos\n",
    "print(\"\\nValores nulos por columna:\")\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d97499",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminar valores nulos\n",
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97c7baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificar valores nulos\n",
    "print(\"\\nValores nulos por columna:\")\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54178f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respuestas por pregunta\n",
    "preguntas = [col for col in dataset.columns if col.startswith('1.') or col.startswith('2.') or col.startswith('3.')or col.startswith('4.')or col.startswith('5.')\n",
    "             or col.startswith('6.') or col.startswith('7.') or col.startswith('8.') or col.startswith('9.') or col.startswith('10.')]\n",
    "print(\"Cantidad de respuestas por pregunta:\")\n",
    "for pregunta in preguntas:\n",
    "    print(f\"{pregunta}: {dataset[pregunta].notnull().sum()} respuestas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a354f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorias de las preguntas\n",
    "categorias = {\n",
    "    \"Alegría\": [\"1.\", \"6.\"],\n",
    "    \"Tristeza\": [\"2.\"],\n",
    "    \"Estrés\": [\"3.\", \"9.\"],\n",
    "    \"Inquietud/Preocupación\": [\"4.\", \"5.\"],\n",
    "    \"Miedo\": [\"7.\", \"10.\"],\n",
    "    \"Enojo\": [\"8.\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25af41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frecuencia de categorías de sentimiento\n",
    "frecuencias = {}\n",
    "for categoria, preguntas_cat in categorias.items():\n",
    "    # Filtrar columnas que coincidan con los prefijos dados\n",
    "    columnas = [col for col in dataset.columns if any(col.startswith(p) for p in preguntas_cat)]\n",
    "    # Contar respuestas no nulas en estas columnas\n",
    "    total_respuestas = dataset[columnas].notnull().sum().sum()\n",
    "    frecuencias[categoria] = total_respuestas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce82b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFrecuencia de respuestas por categoría de sentimiento:\")\n",
    "print(frecuencias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f5d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de frecuencias corregidas\n",
    "sns.barplot(x=list(frecuencias.keys()), y=list(frecuencias.values()))\n",
    "plt.title(\"Distribución de Sentimientos en el Dataset\")\n",
    "plt.xlabel(\"Categoría de Sentimiento\")\n",
    "plt.ylabel(\"Número de Respuestas\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ac930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for categoria, frecuencia in frecuencias.items():\n",
    "    print(f\"{categoria}: {frecuencia}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc4e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_nube_palabras(data, columnas, titulo):\n",
    "    # Concatenar respuestas en una sola cadena, asegurando que todo sea texto\n",
    "    texto = \" \".join(data[columnas].fillna(\"\").astype(str).sum(axis=1))\n",
    "    \n",
    "    # Crear la nube de palabras\n",
    "    nube = WordCloud(width=800, height=400, background_color=\"white\", colormap=\"viridis\").generate(texto)\n",
    "    \n",
    "    # Mostrar la nube de palabras\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(nube, interpolation=\"bilinear\")\n",
    "    plt.title(titulo, fontsize=16)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f818e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar nube de palabras para cada sentimiento\n",
    "for sentimiento, preguntas_cat in categorias.items():\n",
    "    columnas = [col for col in dataset.columns if any(col.startswith(p) for p in preguntas_cat)]\n",
    "    generar_nube_palabras(dataset, columnas, f\"Nube de Palabras - {sentimiento}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec74e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def palabras_frecuentes(data, columnas, titulo, top_n=10):\n",
    "    \"\"\"\n",
    "    Identificar las palabras más frecuentes en un conjunto de textos.\n",
    "    \"\"\"\n",
    "    # Concatenar todas las respuestas en una sola cadena\n",
    "    texto = \" \".join(data[columnas].fillna(\"\").astype(str).sum(axis=1))\n",
    "    \n",
    "    # Preprocesar el texto: convertir a minúsculas y eliminar caracteres especiales\n",
    "    texto_limpio = re.sub(r\"[^a-zA-ZáéíóúñÑ\\s]\", \"\", texto.lower())\n",
    "    \n",
    "    # Tokenizar el texto\n",
    "    palabras = texto_limpio.split()\n",
    "    \n",
    "    # Filtrar palabras vacías (stopwords)\n",
    "    palabras = [palabra for palabra in palabras if palabra not in stop_words]\n",
    "    \n",
    "    # Contar la frecuencia de cada palabra\n",
    "    conteo = Counter(palabras)\n",
    "    \n",
    "    # Obtener las palabras más comunes\n",
    "    palabras_comunes = conteo.most_common(top_n)\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    print(f\"Palabras más frecuentes para {titulo}:\")\n",
    "    for palabra, frecuencia in palabras_comunes:\n",
    "        print(f\"{palabra}: {frecuencia}\")\n",
    "    \n",
    "    # Visualizar con una gráfica de barras\n",
    "    palabras, frecuencias = zip(*palabras_comunes)\n",
    "    plt.bar(palabras, frecuencias)\n",
    "    plt.title(f\"Palabras más frecuentes - {titulo}\")\n",
    "    plt.xlabel(\"Palabras\")\n",
    "    plt.ylabel(\"Frecuencia\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff4fccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar palabras clave para cada sentimiento\n",
    "for sentimiento, preguntas_cat in categorias.items():\n",
    "    columnas = [col for col in dataset.columns if any(col.startswith(p) for p in preguntas_cat)]\n",
    "    palabras_frecuentes(dataset, columnas, sentimiento, top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98942ac3",
   "metadata": {},
   "source": [
    "<h1> Preprocesamiento de Texto </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb771a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fc18e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_texto(texto):\n",
    "    # Convertir a minúsculas\n",
    "    texto = texto.lower()\n",
    "    # Eliminar caracteres especiales y números\n",
    "    texto = re.sub(r\"[^a-záéíóúñ\\s]\", \"\", texto)\n",
    "    # Eliminar números\n",
    "    texto = re.sub(r\"\\d+\", \"\", texto)\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db674c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_texto(texto, stop_words, lematizar=True):\n",
    "    texto_limpio = limpiar_texto(texto)\n",
    "    palabras = texto_limpio.split()  # Tokenización\n",
    "    palabras = [palabra for palabra in palabras if palabra not in stop_words]  # Eliminar stopwords\n",
    "    \n",
    "    # Lematización o stemming\n",
    "    if lematizar:\n",
    "        palabras = [lemmatizer.lemmatize(palabra) for palabra in palabras]\n",
    "    else:\n",
    "        palabras = [stemmer.stem(palabra) for palabra in palabras]\n",
    "    return \" \".join(palabras)  # Reunir palabras en un solo string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2c5442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función de procesamiento general\n",
    "def procesar_todas_las_columnas(dataset, stop_words):\n",
    "    \"\"\"\n",
    "    Aplica procesamiento a todas las columnas del dataset.\n",
    "    - Limpia texto para columnas de texto.\n",
    "    - Convierte valores numéricos o categóricos en cadenas para consistencia.\n",
    "    \"\"\"\n",
    "    for col in dataset.columns:\n",
    "        dataset[col] = dataset[col].fillna(\"\").apply(\n",
    "            lambda x: procesar_texto(str(x), stop_words) if isinstance(x, str) else str(x)\n",
    "        )\n",
    "    return dataset\n",
    "\n",
    "# Aplicar la función al dataset completo\n",
    "dataset = procesar_todas_las_columnas(dataset, stop_words)\n",
    "\n",
    "# Verificar los resultados\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64db5d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = procesar_todas_las_columnas(dataset, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314d8dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nVista preliminar del Dataset:\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e96d83",
   "metadata": {},
   "source": [
    "<h1>Categorias y frecuencia</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c958bb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un diccionario para almacenar las respuestas por categoría\n",
    "respuestas_por_categoria = {}\n",
    "\n",
    "for categoria, preguntas_cat in categorias.items():\n",
    "    # Filtrar columnas asociadas a la categoría\n",
    "    columnas = [col for col in dataset.columns if any(col.startswith(p) for p in preguntas_cat)]\n",
    "    # Combinar todas las respuestas de estas columnas\n",
    "    respuestas_por_categoria[categoria] = dataset[columnas].fillna(\"\").apply(lambda x: \" \".join(x), axis=1)\n",
    "\n",
    "# Convertir el diccionario a un DataFrame para inspección (opcional)\n",
    "respuestas_df = pd.DataFrame(respuestas_por_categoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d88b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar las primeras filas del DataFrame\n",
    "print(respuestas_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58c7636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar todos los textos del dataset en una lista para la vectorización\n",
    "textos = dataset.apply(lambda row: \" \".join(row.astype(str)), axis=1)\n",
    "\n",
    "# Configurar el vectorizador TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=500)  # Limitar a 500 características principales\n",
    "tfidf_matrix = vectorizer.fit_transform(textos)\n",
    "\n",
    "# Convertir a DataFrame para inspección\n",
    "import pandas as pd\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Verificar el resultado\n",
    "print(tfidf_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403dac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspeccionar las palabras más relevantes en el primer documento\n",
    "palabras_importantes = tfidf_df.iloc[0].sort_values(ascending=False).head(10)\n",
    "print(palabras_importantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c1c7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total de características seleccionadas: {tfidf_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070cce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfidf_matrix.shape)\n",
    "print(tfidf_matrix.nnz)  # Número de elementos no nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eeda55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un mapa de calor para una muestra (por ejemplo, las primeras 50 palabras)\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(tfidf_df.iloc[:50, :].T, cmap=\"YlGnBu\", cbar=True, xticklabels=False, yticklabels=vectorizer.get_feature_names_out())\n",
    "plt.title(\"Mapa de Calor de la Matriz TF-IDF\")\n",
    "plt.xlabel(\"Documentos\")\n",
    "plt.ylabel(\"Palabras\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f09d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar todas las columnas relacionadas con las preguntas\n",
    "dataset['Texto_Procesado'] = dataset[\n",
    "    [col for col in dataset.columns if col.startswith(tuple(str(i) for i in range(1, 11)))]\n",
    "].apply(lambda x: \" \".join(x), axis=1)\n",
    "\n",
    "# Vectorizar el texto procesado usando TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=500)  # Puedes ajustar el número máximo de características\n",
    "tfidf_matrix = vectorizer.fit_transform(dataset['Texto_Procesado'])\n",
    "\n",
    "# Convertir a DataFrame para inspección\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "print(tfidf_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558283f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar las 20 palabras más frecuentes (mayores valores TF-IDF promedio)\n",
    "top_words = tfidf_df.mean().sort_values(ascending=False).head(20).index\n",
    "\n",
    "# Filtrar la matriz TF-IDF para estas palabras\n",
    "tfidf_top = tfidf_df[top_words]\n",
    "\n",
    "# Visualizar con un mapa de calor\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(tfidf_top.T, cmap=\"viridis\", annot=False, cbar=True, yticklabels=top_words)\n",
    "plt.title(\"Mapa de Calor de la Matriz TF-IDF (Top 20 Palabras)\")\n",
    "plt.xlabel(\"Fila\")\n",
    "plt.ylabel(\"Palabras\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b92299a",
   "metadata": {},
   "source": [
    "<h1> Generacion de Embeddings usando Transformers </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2f36a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del modelo\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Cargar modelo y tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME).to(device)\n",
    "model.eval()\n",
    "\n",
    "# Función para generar embeddings en lotes\n",
    "def generar_embeddings_batch(textos, batch_size=16):\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(textos), batch_size)):\n",
    "            batch_textos = textos[i:i + batch_size]\n",
    "            inputs = tokenizer(batch_textos, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "            inputs = {key: val.to(device) for key, val in inputs.items()}  # Mover inputs a GPU\n",
    "            outputs = model(**inputs)\n",
    "            batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()  # CLS token\n",
    "            embeddings.extend(batch_embeddings)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Generar embeddings para los textos procesados\n",
    "textos = dataset['Texto_Procesado'].fillna(\"\").tolist()\n",
    "embeddings = generar_embeddings_batch(textos, batch_size=16)\n",
    "\n",
    "# Convertir a DataFrame para inspección (opcional)\n",
    "embeddings_df = pd.DataFrame(embeddings)\n",
    "print(embeddings_df.head())\n",
    "\n",
    "# Guardar los embeddings en el dataset\n",
    "dataset[\"Embeddings\"] = list(embeddings)\n",
    "\n",
    "# Guardar los embeddings en un archivo\n",
    "np.save(\"embeddings.npy\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668df485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora obtenemos los embeddings guardados\n",
    "print(dataset[\"Embeddings\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce46915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducir la dimensionalidad a 2D con PCA\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_pca = pca.fit_transform(embeddings)\n",
    "\n",
    "# Visualizar los embeddings\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(embeddings_pca[:, 0], embeddings_pca[:, 1], c='blue', alpha=0.5)\n",
    "plt.title(\"Visualización de Embeddings (PCA)\")\n",
    "plt.xlabel(\"Componente Principal 1\")\n",
    "plt.ylabel(\"Componente Principal 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3b2e6e",
   "metadata": {},
   "source": [
    "<h1> Division de DataSet </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa66e10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Distribución de clases en la columna 'Sentimientos':\")\n",
    "print(respuestas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae6ea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar características (X) y etiquetas (y)\n",
    "X = embeddings  # Usaremos los embeddings generados como características\n",
    "y = respuestas_df  # Las etiquetas de sentimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708428a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f89983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b538584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# División del dataset (80% entrenamiento, 20% prueba) manteniendo la proporción de clases\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e803800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar la distribución de clases\n",
    "print(\"Distribución de clases en el conjunto completo:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "print(\"\\nDistribución de clases en el conjunto de entrenamiento:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print(\"\\nDistribución de clases en el conjunto de prueba:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cab95ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar una nueva división estratificada\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Verificar nuevamente la distribución\n",
    "print(\"Distribución de clases después de la nueva división:\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2a7bc8",
   "metadata": {},
   "source": [
    "<h1>Modelos</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2be5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo KNN \n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "print(\"KNN\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# Naive Bayes\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "print(\"\\nNaive Bayes\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_nb))\n",
    "\n",
    "id3 = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "id3.fit(X_train, y_train)\n",
    "y_pred_id3 = id3.predict(X_test)\n",
    "print(\"\\nID3\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_id3))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_id3))\n",
    "print(\"Tree Structure:\\n\", export_text(id3, feature_names=list(X.columns)))\n",
    "\n",
    "c45 = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
    "c45.fit(X_train, y_train)\n",
    "y_pred_c45 = c45.predict(X_test)\n",
    "print(\"\\nC4.5\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_c45))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_c45))\n",
    "print(\"Tree Structure:\\n\", export_text(c45, feature_names=list(X.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7702f40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar sobremuestreo\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Verificar la distribución después del sobremuestreo\n",
    "print(\"Distribución de clases después del sobremuestreo:\")\n",
    "print(pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2846267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar SVM con kernel lineal\n",
    "svm_linear = SVC(kernel=\"linear\", C=1, random_state=42)\n",
    "svm_linear.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "y_pred_svm_linear = svm_linear.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento\n",
    "print(\"\\n--- Resultados para SVM (Kernel Lineal) ---\")\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(confusion_matrix(y_test, y_pred_svm_linear))\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred_svm_linear))\n",
    "print(f\"Precisión: {accuracy_score(y_test, y_pred_svm_linear):.2f}\")\n",
    "\n",
    "# Probar SVM con kernel RBF\n",
    "svm_rbf = SVC(kernel=\"rbf\", C=1, gamma=0.1, random_state=42)\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "y_pred_svm_rbf = svm_rbf.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento\n",
    "print(\"\\n--- Resultados para SVM (Kernel RBF) ---\")\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(confusion_matrix(y_test, y_pred_svm_rbf))\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred_svm_rbf))\n",
    "print(f\"Precisión: {accuracy_score(y_test, y_pred_svm_rbf):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1614f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
